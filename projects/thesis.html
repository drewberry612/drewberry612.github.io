<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MSc Thesis: Neural Network Driving Agents</title>
    <link rel="stylesheet" href="../styles/thesis.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/slick-carousel/slick/slick.css"/>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/slick-carousel/slick/slick.min.js"></script>
    <script src="../scripts/video-carousel.js"></script>
</head>
<body>
    <header>
        <h1>MSc Thesis: Neural Network Driving Agents</h1>
    </header>
    <main>
        <p><a href="https://github.com/drewberry612/torcs-research" target="_blank">View on GitHub</a></p>
        <section>
            <p>ðŸ“š MSc Thesis: "Using Machine Learning Techniques to Create Neural Network Driving Agents, with a Focus on Reinforcement Learning"</p>
            <p>For my MSc thesis, I trained AI driving agents using a genetic algorithm and the PPO reinforcement learning algorithm. The TORCS (The Open Racing Car Simulator) was used as the environment for training these agents.</p>
        </section>
        <h2>Demo</h2>
        <section>
            <div class="video-carousel">
                <div data-title="Demo Video">
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/CAuWCjPuZnc" 
                        title="Demo Video" 
                        frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen>
                    </iframe>
                </div>
                <div data-title="Training Process">
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/EXAMPLE1" 
                        title="Training Process" 
                        frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen>
                    </iframe>
                </div>
                <div data-title="Agent Performance">
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/EXAMPLE2" 
                        title="Agent Performance" 
                        frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen>
                    </iframe>
                </div>
                <div data-title="Comparison of Algorithms">
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/EXAMPLE3" 
                        title="Comparison of Algorithms" 
                        frameborder="0" 
                        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                        allowfullscreen>
                    </iframe>
                </div>
            </div>
        </section>
        <h2>ðŸŽ® Project Overview</h2>
        <section>
            <p>The Open Racing Car Simulator (TORCS) is a racing simulation game where players race against computer-controlled opponents. In this project, I developed several AI agents for the game, using various machine learning techniques on neural networks. These agents were trained to complete laps efficiently and compete with human players.</p>
            <p>The focus was on genetic algorithms and reinforcement learning (PPO), which were tested and compared to determine their effectiveness in training the AI agents.</p>
        </section>
        <h2>ðŸ§  Machine Learning Approach</h2>
        <section>
            <p><strong>Genetic Algorithm (GA):</strong> A form of evolutionary algorithm that uses a population of agents and evolves them through selection, crossover, and mutation. This method was experimented with in-depth to create agents that could successfully navigate the racing environment.</p>
            <p><strong>PPO (Proximal Policy Optimization):</strong> A reinforcement learning algorithm that was used to train agents to make decisions based on rewards and penalties in the racing environment.</p>
            <p>These algorithms were applied to a set of agents, each trained with different configurations, to explore the advantages and challenges of each technique in a racing simulation.</p>
        </section>
        <h2>ðŸš— Racing Simulation Environment</h2>
        <section>
            <p>The TORCS environment offers challenges such as high-speed decision-making and spatial awareness, which closely mimic those faced by real-world autonomous vehicles. The research aimed to uncover insights into the application of machine learning in autonomous driving.</p>
            <p>Each algorithm was carefully tuned to create agents that could follow the track axis and racing lines, simulating behaviors that would be useful in real-world autonomous driving scenarios.</p>
        </section>
        <h2>ðŸ“‘ Abstract</h2>
        <section>
            <p>The Open Racing Car Simulator (TORCS) is a car racing simulation game, which allows a player to race against opponents that are simulated by the computer. In this project, several AI opponents for this game have been developed, using various forms of machine learning on neural networks, which can be observed or raced against. The differences and advantages of genetic and reinforcement learning algorithms have been explored in this racing game context. Each parameter and condition of these algorithms were experimented upon diligently, to create AI agents that could complete laps of a race efficiently and rival human players.</p>
            <p>A racing simulation environment offers a unique set of challenges that are comparable to those faced by real-world autonomous vehicles, such as high-speed decision-making and spatial awareness. The exploration of this idea could uncover insights into the use of machine learning in such contexts.</p>
            <p>This thesis illustrates all experiments and findings, demonstrating the competency of trained agents, while also explaining the technical aspects of how research was conducted. Both algorithms have created simple and complex racing behaviours, such as following the track axis and/or racing line. However, a final model trained using the genetic algorithm demonstrated the best performance.</p>
        </section>
    </main>
    <footer>
        <p>Â© 2025 Drew Berry. References available upon request.</p>
    </footer>
</body>
</html>
