<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kaggle Competitions</title>
    <link rel="stylesheet" href="../styles/kaggle.css">
</head>
<body>
    <header>
        <h1>Kaggle Competitions</h1>
        <div class="cv-link-container">
            <a href="https://github.com/drewberry612/kaggle-comps" target="_blank" class="cv-link">View on GitHub</a>
            <a href="https://www.kaggle.com/drewberry6" target="_blank" class="cv-link">Kaggle Account</a>
        </div>
    </header>
    <main>
        <section>
            <p>This page highlights my ongoing practice and exploration of data science and machine learning through Kaggle competitions. I participate in these challenges in my free time to sharpen my skills and stay updated with the latest in the field.</p>
        </section>
        <h2>Process</h2>
        <section>
            <p>In each Kaggle competition, I approach the challenge as a miniature data science project. The typical process includes:</p>
            <h3>1. Understanding the Problem</h3>
            <p>I begin by reading the competition description and understanding the objective ‚Äî whether it's classification, regression, ranking, etc. I also try to understand what kind of real-world scenario the data represents.</p>
            <h3>2. Data Exploration and Preprocessing</h3>
            <p>I perform exploratory data analysis (EDA) to understand distributions, spot anomalies, and guide preprocessing. This often involves:</p>
            <ul>
                <li>Handling missing values</li>
                <li>Encoding categorical variables</li>
                <li>Creating new features from existing ones</li>
            </ul>
            <h3>3. Model Training and Evaluation</h3>
            <p>I experiment with multiple models (e.g. logistic regression, random forests, gradient boosting), using:</p>
            <ul>
                <li>Cross-validation to assess generalisation</li>
                <li>Hyperparameter tuning via grid/random search or Optuna</li>
            </ul>
            <h3>4. Submission and Iteration</h3>
            <p>Once I have a promising model, I generate predictions for the test set and submit to Kaggle. I track public leaderboard scores and iterate accordingly.</p>
            <h3>5. Result Interpretation</h3>
            <p>After the competition or submission phase, I analyse:</p>
            <ul>
                <li>What worked and what didn‚Äôt</li>
                <li>The impact of specific features</li>
                <li>Model performance trade-offs</li>
            </ul>
        </section>
        <h2>Competitions</h2>
        <section>
            <table>
                <thead>
                    <tr>
                        <th>üèÖ Competition</th>
                        <th>üìä Final Score</th>
                        <th>üí• Top Competitor Scores</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>üöÄ Spaceship Titanic</td>
                        <td>79%</td>
                        <td>81/82%</td>
                    </tr>
                </tbody>
            </table>
        </section>
        <section class="skills-stack-container">
            <div class="skills-box-container">
                <h2>Skills</h2>
                <div class="skills-box">
                    <ul>
                        <li>Data Analysis</li>
                        <li>Machine Learning</li>
                        <li>Feature Engineering</li>
                        <li>Model Evaluation</li>
                        <li>Hyperparameter Tuning</li>
                        <li>Data Visualisation</li>
                        <li>Python Programming</li>
                    </ul>
                </div>
            </div>
            <div class="stack-box-container">
                <h2>Tech Stack</h2>
                <div class="stack-box">
                    <ul>
                        <li>Python</li>
                        <li>Pandas</li>
                        <li>NumPy</li>
                        <li>Scikit-learn</li>
                        <li>Matplotlib</li>
                        <li>Seaborn</li>
                        <li>Kaggle API</li>
                    </ul>
                </div>
            </div>
        </section>
    </main>
    <footer>
        <p>¬© 2025 Drew Berry. References available upon request.</p>
    </footer>
</body>
</html>
